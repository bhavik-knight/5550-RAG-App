# RAG Application - Nova Scotia Road Safety Expert

A Retrieval-Augmented Generation (RAG) system specialized in the Nova Scotia Driver's Handbook. This application features a multi-layered security architecture and an evaluation engine to ensure faithful and safe answers.

## Quick Links
- **Test Results**: [output/results.txt](file:///home/bhavik/Dropbox/edu/smu/winter/mobile_dev/rag-app/output/results.txt)
- **Security Audit Log**: [logs/security.log](file:///home/bhavik/Dropbox/edu/smu/winter/mobile_dev/rag-app/logs/security.log)

## Architecture

- **Embeddings**: Jina AI (`jina-embeddings-v4`)
- **LLM**: Liquid LFM 2.5 1.2B Instruct via **OpenRouter**
- **Vector Store**: ChromaDB
- **Framework**: LangChain

## Key Security Features

### Prompt Injection Defenses
We have implemented **5 layers of defense** against prompt injection and instruction leakage:

1.  **System Prompt Hardening**: A strict internal persona that mandates topical adherence and forbids the disclosure of internal instructions.
2.  **Input Sanitization**: A regex-based scanner that detects and blocks common injection patterns (e.g., "ignore previous instructions", "print your system prompt").
3.  **Instruction-Data Separation**: All retrieved context is wrapped in clear `<retrieved_context>` delimiters to help the LLM distinguish between system instructions and untrusted data.
4.  **Output Integrity Validation**: The system scans LLM responses for fragments of the system prompt or indicators that the AI has adopted a prohibited persona.
5.  **Jailbreak Refusal**: Detection of jailbreak keywords (e.g., "DAN") and standardized refusals for non-compliant requests.

### Security Guardrails
- **PII Sanitization**: Automatically redacts emails, phone numbers, and license plates from user queries.
- **Off-Topic Filtering**: Blocks queries unrelated to Nova Scotia road safety using an adaptive keyword whitelist.
- **Execution Limits**: Enforces a strict **30-second timeout** on LLM calls to prevent resource exhaustion.
- **Retrieval Confidence**: Validates that retrieved document chunks meet a minimum similarity threshold.

## Evaluation Metrics

To ensure system reliability, we use two primary evaluation signals:

- **Faithfulness Check**: A numerical score (0.0 to 1.0) generated by an LLM-based evaluator that compares the final answer against the retrieved context to detect hallucinations.
- **Retrieval Relevance**: Tracking the similarity scores of retrieved chunks to ensure the most pertinent information is used.

### Interesting Findings
- **The "Joke" Edge Case**: Queries like "Tell me a joke about driving" initially bypassed off-topic filters because they contained valid keywords ("driving"). However, the **Hardened System Prompt** correctly identifies these as out-of-scope during generation, resulting in a safe refusal.

## Usage

### Setup
1.  **Install**: `uv sync`
2.  **Config**: Create `.env` with `JINA_API_KEY` and `OPENROUTER_API_KEY`.
3.  **Data**: Place `DH-Chapter2.pdf` in the `data/` directory.

### Commands
- **Ingest**: `uv run python3 main.py --mode ingest`
- **Interactive**: `uv run python3 main.py --mode query`
- **Automated Workload**: `uv run python3 main.py --mode automated`

Automated test results are stored in `output/results.txt`.

## Project Structure
```text
rag-app/
├── main.py                # Unified entry point
├── src/
│   ├── security/          # Modular security package (5 defenses)
│   ├── evaluation.py      # Numerical faithfulness tracking
│   ├── rag_query.py       # Production RAG pipeline
│   ├── config.py          # Central configuration
│   └── ...
├── data/                  # Input PDFs
├── output/                # DB and results.txt
└── logs/                  # security.log (Audit trail)
```
